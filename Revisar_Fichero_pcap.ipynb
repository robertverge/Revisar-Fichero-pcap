{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee76828-26ba-4c6b-953c-66280e56b2b6",
   "metadata": {},
   "source": [
    "## Detecta que el fichero sea válido\n",
    "\n",
    "NOTA: Comprueba que sea un .ncap correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeeb631b-a733-4ae0-af0a-817521788fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abriendo archivo: descargas.pcap\n",
      "Tamaño del archivo: 153442222 bytes\n",
      "Magic number: 0xa1b2c3d4\n",
      "\n",
      "Primer paquete encontrado:\n",
      "Timestamp: 1771923568\n",
      "Tamaño capturado: 54 bytes\n",
      "\n",
      "Primeros 32 bytes:\n",
      "b'\\x00\\x10 0@P\\x00\\x1e\\x10\\x1f\\x00\\x00\\x08\\x00E\\x00\\x00(\\xac\\xc3@\\x00\\x80\\x06\\xbe\\x10\\xc0\\xa8\\td\\xc0o'\n",
      "\n",
      "Total paquetes: 185635\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "\n",
    "def comprobar_pcap(path):\n",
    "    print(f\"Abriendo archivo: {path}\")\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(\"ERROR: el archivo no existe\")\n",
    "        return\n",
    "\n",
    "    tamaño = os.path.getsize(path)\n",
    "    print(f\"Tamaño del archivo: {tamaño} bytes\")\n",
    "\n",
    "    if tamaño == 0:\n",
    "        print(\"ERROR: archivo vacío\")\n",
    "        return\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        cabecera = f.read(24)\n",
    "\n",
    "        if len(cabecera) < 24:\n",
    "            print(\"ERROR: archivo demasiado pequeño para ser PCAP\")\n",
    "            return\n",
    "\n",
    "        magic = struct.unpack(\"<I\", cabecera[:4])[0]\n",
    "\n",
    "        print(f\"Magic number: 0x{magic:08x}\")\n",
    "\n",
    "        # contar paquetes\n",
    "        paquetes = 0\n",
    "\n",
    "        while True:\n",
    "            header = f.read(16)\n",
    "            if len(header) < 16:\n",
    "                break\n",
    "\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", header)\n",
    "\n",
    "            data = f.read(incl_len)\n",
    "\n",
    "            if paquetes == 0:\n",
    "                print(\"\\nPrimer paquete encontrado:\")\n",
    "                print(f\"Timestamp: {ts_sec}\")\n",
    "                print(f\"Tamaño capturado: {incl_len} bytes\")\n",
    "\n",
    "                print(\"\\nPrimeros 32 bytes:\")\n",
    "                print(data[:32])\n",
    "\n",
    "            paquetes += 1\n",
    "\n",
    "        print(f\"\\nTotal paquetes: {paquetes}\")\n",
    "\n",
    "\n",
    "# CAMBIA ESTA RUTA SI HACE FALTA\n",
    "comprobar_pcap(\"descargas.pcap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a8b357-40b8-4b23-b2a1-aec9667f7448",
   "metadata": {},
   "source": [
    "## Lista paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc8de6c1-3ef0-4334-870b-6958c7b8106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquete 1: 192.168.9.100 → 192.111.5.128 (TCP)\n",
      "Paquete 2: 192.168.9.100 → 142.250.200.106 (TCP)\n",
      "Paquete 3: 142.250.200.106 → 192.168.9.100 (TCP)\n",
      "Paquete 4: 52.97.117.50 → 192.168.9.100 (UDP)\n",
      "Paquete 5: 192.168.9.100 → 52.97.117.50 (UDP)\n",
      "Paquete 6: 142.250.200.106 → 192.168.9.100 (TCP)\n",
      "Paquete 7: 192.168.9.100 → 142.250.200.106 (TCP)\n",
      "Paquete 8: 192.168.9.100 → 172.217.168.170 (TCP)\n",
      "Paquete 9: 142.250.200.106 → 192.168.9.100 (TCP)\n",
      "Paquete 10: 172.217.168.170 → 192.168.9.100 (TCP)\n",
      "Paquete 11: 192.168.9.100 → 192.168.9.1 (UDP)\n",
      "Paquete 12: 192.168.9.100 → 208.67.222.222 (UDP)\n",
      "Paquete 13: 192.168.9.100 → 52.97.117.50 (UDP)\n",
      "Paquete 14: 192.168.9.1 → 192.168.9.100 (UDP)\n",
      "Paquete 15: 172.217.168.170 → 192.168.9.100 (TCP)\n",
      "Paquete 16: 142.250.200.106 → 192.168.9.100 (TCP)\n",
      "Paquete 17: 172.217.168.170 → 192.168.9.100 (TCP)\n",
      "Paquete 18: 172.217.168.170 → 192.168.9.100 (TCP)\n",
      "Paquete 19: 192.168.9.100 → 172.217.168.170 (TCP)\n",
      "Paquete 20: 192.168.9.100 → 216.239.38.223 (TCP)\n",
      "\n",
      "Total paquetes leídos: 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "\n",
    "def ip_to_str(ip_bytes):\n",
    "    return socket.inet_ntoa(ip_bytes)\n",
    "\n",
    "def analizar_pcap(path):\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        print(\"Archivo no existe\")\n",
    "        return\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "\n",
    "        # saltar cabecera global\n",
    "        f.read(24)\n",
    "\n",
    "        paquetes = 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            header = f.read(16)\n",
    "            if len(header) < 16:\n",
    "                break\n",
    "\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", header)\n",
    "\n",
    "            data = f.read(incl_len)\n",
    "\n",
    "            paquetes += 1\n",
    "\n",
    "            # comprobar que hay Ethernet + IP\n",
    "            if len(data) < 34:\n",
    "                continue\n",
    "\n",
    "            eth_type = struct.unpack(\"!H\", data[12:14])[0]\n",
    "\n",
    "            # 0x0800 = IPv4\n",
    "            if eth_type == 0x0800:\n",
    "\n",
    "                ip_header = data[14:34]\n",
    "\n",
    "                proto = ip_header[9]\n",
    "\n",
    "                src_ip = ip_to_str(ip_header[12:16])\n",
    "                dst_ip = ip_to_str(ip_header[16:20])\n",
    "\n",
    "                proto_name = {\n",
    "                    1: \"ICMP\",\n",
    "                    6: \"TCP\",\n",
    "                    17: \"UDP\"\n",
    "                }.get(proto, str(proto))\n",
    "\n",
    "                print(f\"Paquete {paquetes}: {src_ip} → {dst_ip} ({proto_name})\")\n",
    "\n",
    "                # solo mostrar primeros 20\n",
    "                if paquetes >= 20:\n",
    "                    break\n",
    "\n",
    "        print(f\"\\nTotal paquetes leídos: {paquetes}\")\n",
    "\n",
    "\n",
    "analizar_pcap(r\"descargas.pcap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3550946-0247-4d28-bd99-d03433f06a58",
   "metadata": {},
   "source": [
    "## Resumen de paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74961ef8-fe2c-4c41-9386-3c7c908da628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 192.168.9.100:64999 → 192.111.5.128:443 (TCP) len=54\n",
      "#2 192.168.9.100:49328 → 142.250.200.106:443 (TCP) len=809\n",
      "#3 142.250.200.106:443 → 192.168.9.100:49328 (TCP) len=54\n",
      "#4 52.97.117.50:443 → 192.168.9.100:56866 (UDP) len=81\n",
      "#5 192.168.9.100:56866 → 52.97.117.50:443 (UDP) len=81\n",
      "#6 142.250.200.106:443 → 192.168.9.100:49328 (TCP) len=434\n",
      "#7 192.168.9.100:49328 → 142.250.200.106:443 (TCP) len=1171\n",
      "#8 192.168.9.100:64996 → 172.217.168.170:443 (TCP) len=720\n",
      "#9 142.250.200.106:443 → 192.168.9.100:49328 (TCP) len=54\n",
      "#10 172.217.168.170:443 → 192.168.9.100:64996 (TCP) len=54\n",
      "#11 192.168.9.100:58140 → 192.168.9.1:53 (UDP) len=109\n",
      "#12 192.168.9.100:58142 → 208.67.222.222:443 (UDP) len=366\n",
      "#13 192.168.9.100:56866 → 52.97.117.50:443 (UDP) len=77\n",
      "#14 192.168.9.1:53 → 192.168.9.100:58140 (UDP) len=129\n",
      "#15 172.217.168.170:443 → 192.168.9.100:64996 (TCP) len=411\n",
      "#16 142.250.200.106:443 → 192.168.9.100:49328 (TCP) len=356\n",
      "#17 172.217.168.170:443 → 192.168.9.100:64996 (TCP) len=117\n",
      "#18 172.217.168.170:443 → 192.168.9.100:64996 (TCP) len=138\n",
      "#19 192.168.9.100:64996 → 172.217.168.170:443 (TCP) len=54\n",
      "#20 192.168.9.100:65378 → 216.239.38.223:443 (TCP) len=78\n",
      "#21 192.168.9.100:65376 → 216.239.38.223:443 (TCP) len=78\n",
      "#22 192.168.9.100:65378 → 216.239.38.223:443 (TCP) len=54\n",
      "#23 192.168.9.100:65376 → 216.239.38.223:443 (TCP) len=54\n",
      "#24 208.67.222.222:443 → 192.168.9.100:58142 (UDP) len=346\n",
      "#25 192.168.9.100:58143 → 192.168.9.1:53 (UDP) len=86\n",
      "#27 52.97.117.50:443 → 192.168.9.100:56866 (UDP) len=70\n",
      "#28 192.168.9.100:49328 → 142.250.200.106:443 (TCP) len=54\n",
      "#30 216.239.38.223:443 → 192.168.9.100:65376 (TCP) len=54\n",
      "#31 216.239.38.223:443 → 192.168.9.100:65378 (TCP) len=54\n",
      "#32 192.168.9.100:65004 → 142.251.142.138:443 (TCP) len=66\n",
      "\n",
      "Resumen\n",
      "Total paquetes leídos: 185635\n",
      "\n",
      "Top 10 conversaciones (src → dst, proto) por nº de paquetes:\n",
      "  27000  77.209.227.96 → 192.168.9.100  TCP\n",
      "  13538  142.250.200.99 → 192.168.9.100  TCP\n",
      "  10915  104.90.205.185 → 192.168.9.100  UDP\n",
      "   9008  192.168.9.100 → 77.209.227.96  TCP\n",
      "   8829  212.145.41.98 → 192.168.9.100  TCP\n",
      "   5605  172.217.17.4 → 192.168.9.100  TCP\n",
      "   4285  192.168.9.100 → 208.67.222.222  TCP\n",
      "   4172  23.40.114.46 → 192.168.9.100  TCP\n",
      "   4163  184.31.3.35 → 192.168.9.100  TCP\n",
      "   3984  192.168.9.100 → 142.250.200.99  TCP\n",
      "\n",
      "Top 10 puertos (TCP/UDP) más vistos:\n",
      "  149393  TCP  puerto 443\n",
      "  35916  TCP  puerto 58246\n",
      "  26219  UDP  puerto 443\n",
      "  16518  TCP  puerto 55610\n",
      "  12766  UDP  puerto 56707\n",
      "  11624  TCP  puerto 62984\n",
      "   8852  TCP  puerto 57701\n",
      "   5875  TCP  puerto 58806\n",
      "   5011  TCP  puerto 51549\n",
      "   3906  TCP  puerto 58301\n",
      "\n",
      "Top 10 DNS queries (sin compresión):\n",
      "     46  debug.opendns.com\n",
      "     10  api-ipv4.opendns.com\n",
      "     10  sparkcdneus2.azureedge.net\n",
      "      6  tndumbrella.intranet.gencat.cat\n",
      "      4  api.id5-sync.com\n",
      "      4  cm.g.doubleclick.net\n",
      "      4  ep1.adtrafficquality.google\n",
      "      4  a28b00bf6b6d799285cd0b0c810ce5c5.safeframe.googlesyndication.com\n",
      "      4  b.6sc.co\n",
      "      4  c.6sc.co\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "from collections import Counter\n",
    "\n",
    "def ip_to_str(b): \n",
    "    return socket.inet_ntoa(b)\n",
    "\n",
    "def safe_ascii_preview(b, n=200):\n",
    "    # intenta sacar texto visible sin petar\n",
    "    try:\n",
    "        s = b[:n].decode(\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    s = s.replace(\"\\r\", \"\\\\r\").replace(\"\\n\", \"\\\\n\")\n",
    "    return s\n",
    "\n",
    "def parse_dns_name(payload, offset):\n",
    "    # parser DNS name muy simple (sin compresión por punteros para mantener robustez)\n",
    "    labels = []\n",
    "    i = offset\n",
    "    while i < len(payload):\n",
    "        l = payload[i]\n",
    "        if l == 0:\n",
    "            i += 1\n",
    "            break\n",
    "        # si hay compresión (puntero), salimos para no liarla\n",
    "        if (l & 0xC0) == 0xC0:\n",
    "            return None\n",
    "        i += 1\n",
    "        if i + l > len(payload):\n",
    "            return None\n",
    "        labels.append(payload[i:i+l].decode(\"utf-8\", errors=\"ignore\"))\n",
    "        i += l\n",
    "    if not labels:\n",
    "        return None\n",
    "    return \".\".join(labels)\n",
    "\n",
    "def analizar_pcap(path, max_print=30):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"ERROR: archivo no existe\")\n",
    "        return\n",
    "\n",
    "    if os.path.getsize(path) < 24:\n",
    "        print(\"ERROR: demasiado pequeño para PCAP\")\n",
    "        return\n",
    "\n",
    "    conv = Counter()\n",
    "    puertos = Counter()\n",
    "    dns_queries = Counter()\n",
    "\n",
    "    mostrados = 0\n",
    "    total = 0\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        f.read(24)  # global header\n",
    "\n",
    "        while True:\n",
    "            ph = f.read(16)\n",
    "            if len(ph) < 16:\n",
    "                break\n",
    "\n",
    "            # asumimos endianness little (como en tu ejemplo que funcionó)\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", ph)\n",
    "\n",
    "            data = f.read(incl_len)\n",
    "            if len(data) < incl_len:\n",
    "                break\n",
    "\n",
    "            total += 1\n",
    "\n",
    "            # Ethernet mínimo\n",
    "            if len(data) < 14:\n",
    "                continue\n",
    "\n",
    "            eth_type = struct.unpack(\"!H\", data[12:14])[0]\n",
    "            if eth_type != 0x0800:  # IPv4\n",
    "                continue\n",
    "\n",
    "            # IPv4 header mínimo\n",
    "            if len(data) < 14 + 20:\n",
    "                continue\n",
    "\n",
    "            ip_start = 14\n",
    "            ver_ihl = data[ip_start]\n",
    "            ihl = (ver_ihl & 0x0F) * 4\n",
    "            if ihl < 20:\n",
    "                continue\n",
    "            if len(data) < ip_start + ihl:\n",
    "                continue\n",
    "\n",
    "            proto = data[ip_start + 9]\n",
    "            src_ip = ip_to_str(data[ip_start+12:ip_start+16])\n",
    "            dst_ip = ip_to_str(data[ip_start+16:ip_start+20])\n",
    "\n",
    "            # conversación por IP/proto\n",
    "            conv[(src_ip, dst_ip, proto)] += 1\n",
    "\n",
    "            l4_start = ip_start + ihl\n",
    "            if len(data) < l4_start + 4:\n",
    "                continue\n",
    "\n",
    "            proto_name = {1:\"ICMP\",6:\"TCP\",17:\"UDP\"}.get(proto, str(proto))\n",
    "\n",
    "            # TCP/UDP: puertos + payload\n",
    "            src_port = dst_port = None\n",
    "            payload = b\"\"\n",
    "\n",
    "            if proto == 6 and len(data) >= l4_start + 20:  # TCP\n",
    "                src_port, dst_port = struct.unpack(\"!HH\", data[l4_start:l4_start+4])\n",
    "                data_offset = (data[l4_start+12] >> 4) * 4\n",
    "                if data_offset >= 20 and len(data) >= l4_start + data_offset:\n",
    "                    payload = data[l4_start+data_offset:]\n",
    "                puertos[(proto_name, src_port)] += 1\n",
    "                puertos[(proto_name, dst_port)] += 1\n",
    "\n",
    "            elif proto == 17 and len(data) >= l4_start + 8:  # UDP\n",
    "                src_port, dst_port, udplen = struct.unpack(\"!HHH\", data[l4_start:l4_start+6])\n",
    "                payload = data[l4_start+8:]\n",
    "                puertos[(proto_name, src_port)] += 1\n",
    "                puertos[(proto_name, dst_port)] += 1\n",
    "\n",
    "                # DNS básico: puerto 53 y query name simple\n",
    "                if src_port == 53 or dst_port == 53:\n",
    "                    # header DNS 12 bytes\n",
    "                    if len(payload) >= 12:\n",
    "                        qdcount = struct.unpack(\"!H\", payload[4:6])[0]\n",
    "                        if qdcount >= 1:\n",
    "                            name = parse_dns_name(payload, 12)\n",
    "                            if name:\n",
    "                                dns_queries[name] += 1\n",
    "\n",
    "            # imprimir algunos paquetes con detalle\n",
    "            if mostrados < max_print:\n",
    "                if src_port is not None:\n",
    "                    print(f\"#{total} {src_ip}:{src_port} → {dst_ip}:{dst_port} ({proto_name}) len={incl_len}\")\n",
    "                else:\n",
    "                    print(f\"#{total} {src_ip} → {dst_ip} ({proto_name}) len={incl_len}\")\n",
    "\n",
    "                # pistas HTTP en claro (solo texto)\n",
    "                prev = safe_ascii_preview(payload, n=200)\n",
    "                if prev.startswith(\"GET \") or prev.startswith(\"POST \") or \"HTTP/1.\" in prev:\n",
    "                    print(\"   HTTP(?)\", prev)\n",
    "                mostrados += 1\n",
    "\n",
    "    print(\"\\nResumen\")\n",
    "    print(f\"Total paquetes leídos: {total}\")\n",
    "\n",
    "    print(\"\\nTop 10 conversaciones (src → dst, proto) por nº de paquetes:\")\n",
    "    for (s, d, p), c in conv.most_common(10):\n",
    "        pn = {1:\"ICMP\",6:\"TCP\",17:\"UDP\"}.get(p, str(p))\n",
    "        print(f\"  {c:5d}  {s} → {d}  {pn}\")\n",
    "\n",
    "    print(\"\\nTop 10 puertos (TCP/UDP) más vistos:\")\n",
    "    for (pn, port), c in puertos.most_common(10):\n",
    "        print(f\"  {c:5d}  {pn}  puerto {port}\")\n",
    "\n",
    "    if dns_queries:\n",
    "        print(\"\\nTop 10 DNS queries (sin compresión):\")\n",
    "        for name, c in dns_queries.most_common(10):\n",
    "            print(f\"  {c:5d}  {name}\")\n",
    "    else:\n",
    "        print(\"\\nDNS queries: no detectadas (puede ser todo DNS cifrado/DoH o compresión/punteros).\")\n",
    "\n",
    "\n",
    "analizar_pcap(r\"descargas.pcap\", max_print=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1476ced1-a7c8-4ee9-b538-e6ce64fceb96",
   "metadata": {},
   "source": [
    "## Top 20 por tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cdf51f1-e830-4038-97c6-70737c2cf437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paquetes leídos: 185635\n",
      "Tamaño min: 42 bytes\n",
      "Tamaño max: 1514 bytes\n",
      "Tamaño medio: 810.58 bytes\n",
      "P50: 1354 bytes | P90: 1354 bytes | P95: 1494 bytes | P99: 1494 bytes\n",
      "\n",
      "Top 20 paquetes más grandes (por tamaño capturado incl_len):\n",
      "  #148592  incl_len= 1514  orig_len= 1514  ts=1771924003.950213\n",
      "  #148605  incl_len= 1514  orig_len= 1514  ts=1771924003.953112\n",
      "  # 41629  incl_len= 1494  orig_len= 1494  ts=1771923692.382848\n",
      "  # 51852  incl_len= 1494  orig_len= 1494  ts=1771923727.040544\n",
      "  # 62862  incl_len= 1494  orig_len= 1494  ts=1771923761.349634\n",
      "  # 62888  incl_len= 1494  orig_len= 1494  ts=1771923761.425631\n",
      "  # 62889  incl_len= 1494  orig_len= 1494  ts=1771923761.425631\n",
      "  # 62892  incl_len= 1494  orig_len= 1494  ts=1771923761.426596\n",
      "  # 62893  incl_len= 1494  orig_len= 1494  ts=1771923761.426596\n",
      "  # 62895  incl_len= 1494  orig_len= 1494  ts=1771923761.427555\n",
      "  # 62896  incl_len= 1494  orig_len= 1494  ts=1771923761.427555\n",
      "  # 62898  incl_len= 1494  orig_len= 1494  ts=1771923761.428557\n",
      "  # 62899  incl_len= 1494  orig_len= 1494  ts=1771923761.428557\n",
      "  # 62901  incl_len= 1494  orig_len= 1494  ts=1771923761.429745\n",
      "  # 62902  incl_len= 1494  orig_len= 1494  ts=1771923761.429745\n",
      "  # 62910  incl_len= 1494  orig_len= 1494  ts=1771923761.430713\n",
      "  # 62911  incl_len= 1494  orig_len= 1494  ts=1771923761.430713\n",
      "  # 62914  incl_len= 1494  orig_len= 1494  ts=1771923761.431592\n",
      "  # 62915  incl_len= 1494  orig_len= 1494  ts=1771923761.431592\n",
      "  # 62917  incl_len= 1494  orig_len= 1494  ts=1771923761.432540\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "from statistics import mean\n",
    "\n",
    "def analizar_tamaños_pcap(path, top_n=20):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"ERROR: archivo no existe\")\n",
    "        return\n",
    "\n",
    "    tamaño_archivo = os.path.getsize(path)\n",
    "    if tamaño_archivo < 24:\n",
    "        print(\"ERROR: demasiado pequeño para PCAP\")\n",
    "        return\n",
    "\n",
    "    tamaños = []\n",
    "    top = []  # lista de tuplas (incl_len, idx, ts_sec, ts_usec, orig_len)\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        f.read(24)  # global header\n",
    "\n",
    "        idx = 0\n",
    "        while True:\n",
    "            ph = f.read(16)\n",
    "            if len(ph) < 16:\n",
    "                break\n",
    "\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", ph)\n",
    "\n",
    "            data = f.read(incl_len)\n",
    "            if len(data) < incl_len:\n",
    "                # archivo truncado: salimos limpio\n",
    "                print(\"Aviso: PCAP truncado (paquete incompleto al final).\")\n",
    "                break\n",
    "\n",
    "            idx += 1\n",
    "            tamaños.append(incl_len)\n",
    "\n",
    "            # mantener top_n sin librerías: insert + sort pequeño\n",
    "            top.append((incl_len, idx, ts_sec, ts_usec, orig_len))\n",
    "            top.sort(key=lambda x: x[0], reverse=True)\n",
    "            if len(top) > top_n:\n",
    "                top.pop()\n",
    "\n",
    "    if not tamaños:\n",
    "        print(\"No se han leído paquetes.\")\n",
    "        return\n",
    "\n",
    "    tamaños_ordenados = sorted(tamaños)\n",
    "\n",
    "    def pct(p):\n",
    "        # percentil simple (nearest-rank)\n",
    "        if not tamaños_ordenados:\n",
    "            return None\n",
    "        k = int(round((p/100) * (len(tamaños_ordenados)-1)))\n",
    "        k = max(0, min(k, len(tamaños_ordenados)-1))\n",
    "        return tamaños_ordenados[k]\n",
    "\n",
    "    total = len(tamaños)\n",
    "    print(f\"Paquetes leídos: {total}\")\n",
    "    print(f\"Tamaño min: {tamaños_ordenados[0]} bytes\")\n",
    "    print(f\"Tamaño max: {tamaños_ordenados[-1]} bytes\")\n",
    "    print(f\"Tamaño medio: {mean(tamaños):.2f} bytes\")\n",
    "    print(f\"P50: {pct(50)} bytes | P90: {pct(90)} bytes | P95: {pct(95)} bytes | P99: {pct(99)} bytes\")\n",
    "\n",
    "    print(f\"\\nTop {top_n} paquetes más grandes (por tamaño capturado incl_len):\")\n",
    "    for incl_len, i, ts_sec, ts_usec, orig_len in top:\n",
    "        print(f\"  #{i:6d}  incl_len={incl_len:5d}  orig_len={orig_len:5d}  ts={ts_sec}.{ts_usec:06d}\")\n",
    "\n",
    "# Uso\n",
    "analizar_tamaños_pcap(r\"descargas.pcap\", top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de82191-262d-47a0-a729-fa30d3229c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexiones TCP vistas: 1609\n",
      "Buscando respuestas HTTP con posibles descargas...\n",
      "\n",
      "Resumen final\n",
      "  Candidatos HTTP detectados: 0\n",
      "  Ficheros guardados: 0\n",
      "  Carpeta salida: extraidos_http\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import struct\n",
    "import socket\n",
    "from collections import defaultdict\n",
    "\n",
    "OUT_DIR = \"extraidos_http\"\n",
    "MAX_BODY = 50 * 1024 * 1024  # 50 MB por seguridad (ajusta si quieres)\n",
    "\n",
    "def ip_to_str(b):\n",
    "    return socket.inet_ntoa(b)\n",
    "\n",
    "def safe_filename(name):\n",
    "    name = name.strip().strip('\"').strip(\"'\")\n",
    "    name = re.sub(r\"[^\\w\\-.() ]+\", \"_\", name)\n",
    "    if not name:\n",
    "        name = \"archivo.bin\"\n",
    "    return name\n",
    "\n",
    "def parse_headers(header_bytes):\n",
    "    # Devuelve (status_line, headers_dict_lower)\n",
    "    text = header_bytes.decode(\"iso-8859-1\", errors=\"ignore\")\n",
    "    lines = text.split(\"\\r\\n\")\n",
    "    status = lines[0] if lines else \"\"\n",
    "    headers = {}\n",
    "    for line in lines[1:]:\n",
    "        if not line or \":\" not in line:\n",
    "            continue\n",
    "        k, v = line.split(\":\", 1)\n",
    "        headers[k.strip().lower()] = v.strip()\n",
    "    return status, headers\n",
    "\n",
    "def decode_chunked(body):\n",
    "    # Decoder chunked robusto: si algo falla, devuelve None\n",
    "    out = bytearray()\n",
    "    i = 0\n",
    "    try:\n",
    "        while True:\n",
    "            j = body.find(b\"\\r\\n\", i)\n",
    "            if j == -1:\n",
    "                return None\n",
    "            size_line = body[i:j].split(b\";\", 1)[0].strip()\n",
    "            size = int(size_line, 16)\n",
    "            i = j + 2\n",
    "            if size == 0:\n",
    "                # puede haber trailers + CRLF final; no nos complicamos\n",
    "                return bytes(out)\n",
    "            if i + size > len(body):\n",
    "                return None\n",
    "            out += body[i:i+size]\n",
    "            i += size\n",
    "            if body[i:i+2] != b\"\\r\\n\":\n",
    "                return None\n",
    "            i += 2\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_pcap_tcp_payloads(path):\n",
    "    \"\"\"\n",
    "    Lee PCAP y produce segmentos TCP por conexión.\n",
    "    Devuelve dict: conn_key -> {'A': [(seq, payload), ...], 'B': [(seq, payload), ...]}\n",
    "    donde A/B son direcciones (endpoint1->endpoint2) y (endpoint2->endpoint1).\n",
    "    \"\"\"\n",
    "    conns = defaultdict(lambda: {\"A\": [], \"B\": []})\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        gh = f.read(24)\n",
    "        if len(gh) < 24:\n",
    "            raise ValueError(\"PCAP demasiado pequeño\")\n",
    "\n",
    "        pkt_idx = 0\n",
    "        while True:\n",
    "            ph = f.read(16)\n",
    "            if len(ph) < 16:\n",
    "                break\n",
    "\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", ph)\n",
    "            data = f.read(incl_len)\n",
    "            if len(data) < incl_len:\n",
    "                break\n",
    "\n",
    "            pkt_idx += 1\n",
    "\n",
    "            # Ethernet\n",
    "            if len(data) < 14:\n",
    "                continue\n",
    "            eth_type = struct.unpack(\"!H\", data[12:14])[0]\n",
    "            if eth_type != 0x0800:  # IPv4\n",
    "                continue\n",
    "\n",
    "            # IP header\n",
    "            if len(data) < 14 + 20:\n",
    "                continue\n",
    "            ip_start = 14\n",
    "            ver_ihl = data[ip_start]\n",
    "            ihl = (ver_ihl & 0x0F) * 4\n",
    "            if ihl < 20 or len(data) < ip_start + ihl:\n",
    "                continue\n",
    "\n",
    "            proto = data[ip_start + 9]\n",
    "            if proto != 6:  # TCP\n",
    "                continue\n",
    "\n",
    "            src_ip = ip_to_str(data[ip_start+12:ip_start+16])\n",
    "            dst_ip = ip_to_str(data[ip_start+16:ip_start+20])\n",
    "\n",
    "            tcp_start = ip_start + ihl\n",
    "            if len(data) < tcp_start + 20:\n",
    "                continue\n",
    "\n",
    "            src_port, dst_port = struct.unpack(\"!HH\", data[tcp_start:tcp_start+4])\n",
    "            seq = struct.unpack(\"!I\", data[tcp_start+4:tcp_start+8])[0]\n",
    "            data_offset = (data[tcp_start+12] >> 4) * 4\n",
    "            if data_offset < 20 or len(data) < tcp_start + data_offset:\n",
    "                continue\n",
    "\n",
    "            payload = data[tcp_start+data_offset:]\n",
    "            if not payload:\n",
    "                continue\n",
    "\n",
    "            # Normalizamos la conexión por endpoints (para tener key estable)\n",
    "            ep1 = (src_ip, src_port)\n",
    "            ep2 = (dst_ip, dst_port)\n",
    "            if ep1 <= ep2:\n",
    "                key = (ep1, ep2)\n",
    "                direction = \"A\"  # ep1->ep2\n",
    "            else:\n",
    "                key = (ep2, ep1)\n",
    "                direction = \"B\"  # ep2->ep1\n",
    "\n",
    "            # Guardamos segmento\n",
    "            conns[key][direction].append((seq, payload))\n",
    "\n",
    "    return conns\n",
    "\n",
    "def assemble_stream(segments, max_bytes=MAX_BODY):\n",
    "    \"\"\"\n",
    "    Ensambla segmentos TCP de forma best-effort:\n",
    "    - Ordena por seq\n",
    "    - Concatena si hay continuidad o solape\n",
    "    Nota: esto NO maneja gaps perfectos, es “robusto” para capturas normales sin pérdidas.\n",
    "    \"\"\"\n",
    "    if not segments:\n",
    "        return b\"\"\n",
    "    segments = sorted(segments, key=lambda x: x[0])\n",
    "    out = bytearray()\n",
    "\n",
    "    cur_seq = segments[0][0]\n",
    "    for seq, payload in segments:\n",
    "        if len(out) >= max_bytes:\n",
    "            break\n",
    "\n",
    "        if seq > cur_seq:\n",
    "            # gap: metemos separador para evitar juntar cosas raras\n",
    "            # (y avanzamos)\n",
    "            gap = seq - cur_seq\n",
    "            # no rellenamos con ceros (podría falsear), solo saltamos\n",
    "            cur_seq = seq\n",
    "\n",
    "        if seq < cur_seq:\n",
    "            # solape: recortamos\n",
    "            overlap = cur_seq - seq\n",
    "            if overlap >= len(payload):\n",
    "                continue\n",
    "            payload = payload[overlap:]\n",
    "\n",
    "        out += payload\n",
    "        cur_seq += len(payload)\n",
    "\n",
    "    return bytes(out)\n",
    "\n",
    "def find_http_responses(stream_bytes):\n",
    "    \"\"\"\n",
    "    Busca respuestas HTTP dentro del stream:\n",
    "    Devuelve lista de dict con info: headers, body, offsets, filename, etc.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        j = stream_bytes.find(b\"HTTP/1.\", i)\n",
    "        if j == -1:\n",
    "            break\n",
    "\n",
    "        # header end\n",
    "        k = stream_bytes.find(b\"\\r\\n\\r\\n\", j)\n",
    "        if k == -1:\n",
    "            break\n",
    "\n",
    "        header_bytes = stream_bytes[j:k]\n",
    "        status, headers = parse_headers(header_bytes)\n",
    "\n",
    "        body_start = k + 4\n",
    "        # Determinar longitud / chunked\n",
    "        te = headers.get(\"transfer-encoding\", \"\").lower()\n",
    "        cl = headers.get(\"content-length\", \"\")\n",
    "        cd = headers.get(\"content-disposition\", \"\")\n",
    "        ct = headers.get(\"content-type\", \"\")\n",
    "\n",
    "        filename = None\n",
    "        m = re.search(r'filename\\*?=(?:UTF-8\\'\\')?(\"?)([^\";\\r\\n]+)\\1', cd, re.IGNORECASE)\n",
    "        if m:\n",
    "            filename = m.group(2)\n",
    "\n",
    "        body = None\n",
    "        extracted = False\n",
    "\n",
    "        if \"chunked\" in te:\n",
    "            # tenemos que encontrar dónde acaba el chunked: intentamos decodificar desde body_start\n",
    "            decoded = decode_chunked(stream_bytes[body_start:])\n",
    "            if decoded is not None and len(decoded) <= MAX_BODY:\n",
    "                body = decoded\n",
    "                extracted = True\n",
    "        else:\n",
    "            try:\n",
    "                n = int(cl) if cl else None\n",
    "            except ValueError:\n",
    "                n = None\n",
    "\n",
    "            if n is not None and 0 <= n <= MAX_BODY and body_start + n <= len(stream_bytes):\n",
    "                body = stream_bytes[body_start:body_start+n]\n",
    "                extracted = True\n",
    "\n",
    "        results.append({\n",
    "            \"offset\": j,\n",
    "            \"status\": status,\n",
    "            \"content_type\": ct,\n",
    "            \"content_length\": cl,\n",
    "            \"transfer_encoding\": te,\n",
    "            \"content_disposition\": cd,\n",
    "            \"filename\": filename,\n",
    "            \"extracted\": extracted,\n",
    "            \"body\": body if extracted else None,\n",
    "        })\n",
    "\n",
    "        # avanzar para buscar siguiente\n",
    "        i = body_start\n",
    "\n",
    "    return results\n",
    "\n",
    "def main(path):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"ERROR: archivo no existe\")\n",
    "        return\n",
    "    if os.path.getsize(path) < 24:\n",
    "        print(\"ERROR: archivo demasiado pequeño\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "    conns = parse_pcap_tcp_payloads(path)\n",
    "\n",
    "    total_candidates = 0\n",
    "    total_saved = 0\n",
    "\n",
    "    print(f\"Conexiones TCP vistas: {len(conns)}\")\n",
    "    print(\"Buscando respuestas HTTP con posibles descargas...\\n\")\n",
    "\n",
    "    for key, dirs in conns.items():\n",
    "        (ip1, p1), (ip2, p2) = key\n",
    "\n",
    "        # Para respuestas HTTP típicas: servidor -> cliente suele ir en dirección contraria al GET\n",
    "        # Pero como no sabemos quién es servidor, escaneamos ambas direcciones.\n",
    "        for dir_name in (\"A\", \"B\"):\n",
    "            stream = assemble_stream(dirs[dir_name])\n",
    "            if not stream:\n",
    "                continue\n",
    "\n",
    "            http_resps = find_http_responses(stream)\n",
    "            if not http_resps:\n",
    "                continue\n",
    "\n",
    "            for r in http_resps:\n",
    "                total_candidates += 1\n",
    "\n",
    "                who = f\"{ip1}:{p1}→{ip2}:{p2} dir={dir_name}\"\n",
    "                print(f\"[HTTP] ({who}) {r['status']}\")\n",
    "                if r[\"content_type\"]:\n",
    "                    print(f\"  Content-Type: {r['content_type']}\")\n",
    "                if r[\"content_length\"]:\n",
    "                    print(f\"  Content-Length: {r['content_length']}\")\n",
    "                if r[\"transfer_encoding\"]:\n",
    "                    print(f\"  Transfer-Encoding: {r['transfer_encoding']}\")\n",
    "                if r[\"content_disposition\"]:\n",
    "                    print(f\"  Content-Disposition: {r['content_disposition']}\")\n",
    "\n",
    "                if r[\"extracted\"] and r[\"body\"] is not None:\n",
    "                    fname = r[\"filename\"]\n",
    "                    if not fname:\n",
    "                        # inventar nombre por tipo o genérico\n",
    "                        ext = \"\"\n",
    "                        if \"pdf\" in (r[\"content_type\"] or \"\").lower():\n",
    "                            ext = \".pdf\"\n",
    "                        elif \"zip\" in (r[\"content_type\"] or \"\").lower():\n",
    "                            ext = \".zip\"\n",
    "                        elif \"json\" in (r[\"content_type\"] or \"\").lower():\n",
    "                            ext = \".json\"\n",
    "                        elif \"html\" in (r[\"content_type\"] or \"\").lower():\n",
    "                            ext = \".html\"\n",
    "                        fname = f\"extraido_{total_saved+1}{ext}\"\n",
    "\n",
    "                    fname = safe_filename(fname)\n",
    "                    out_path = os.path.join(OUT_DIR, fname)\n",
    "\n",
    "                    # evitar sobreescrituras\n",
    "                    base, ext = os.path.splitext(out_path)\n",
    "                    n = 1\n",
    "                    while os.path.exists(out_path):\n",
    "                        out_path = f\"{base}_{n}{ext}\"\n",
    "                        n += 1\n",
    "\n",
    "                    with open(out_path, \"wb\") as wf:\n",
    "                        wf.write(r[\"body\"])\n",
    "\n",
    "                    total_saved += 1\n",
    "                    print(f\"  ✅ Guardado: {out_path} ({len(r['body'])} bytes)\")\n",
    "                else:\n",
    "                    print(\"  ⚠️ No extraíble (puede faltar reensamblado completo, o es HTTPS, o no hay Content-Length/chunked completo).\")\n",
    "\n",
    "                print()\n",
    "\n",
    "    print(\"Resumen final\")\n",
    "    print(f\"  Candidatos HTTP detectados: {total_candidates}\")\n",
    "    print(f\"  Ficheros guardados: {total_saved}\")\n",
    "    print(f\"  Carpeta salida: {OUT_DIR}\")\n",
    "\n",
    "# Cambia ruta si hace falta\n",
    "main(r\"descargas.pcap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149cddc7-df14-4045-9e99-01d1b3227bd7",
   "metadata": {},
   "source": [
    "## Top 20 descargas y dominios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6acc46-9199-4346-b2ed-427942ef40e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flujos TCP detectados (normalizados): 1616\n",
      "SNI (TLS) detectados: 43\n",
      "\n",
      "Top 20 posibles 'descargas' (bytes servidor→cliente = s2c):\n",
      "- 192.168.9.100:58246 → 77.209.227.96:443  s2c=33.2MB  c2s=16.1KB  ratio~2106.7\n",
      "- 192.168.9.100:55610 → 142.250.200.99:443  s2c=15.8MB  c2s=6.0KB  ratio~2716.3\n",
      "- 192.168.9.100:62984 → 212.145.41.98:443  s2c=10.8MB  c2s=6.8KB  ratio~1617.0\n",
      "- 192.168.9.100:58806 → 23.40.114.46:443  s2c=4.9MB  c2s=49.3KB  ratio~101.2\n",
      "- 192.168.9.100:51549 → 184.31.3.35:443  s2c=4.3MB  c2s=9.5KB  ratio~461.9\n",
      "- 192.168.9.100:57701 → 172.217.17.4:443  s2c=3.9MB  c2s=1.5MB  ratio~2.5\n",
      "- 192.168.9.100:58301 → 82.98.170.158:443  s2c=3.8MB  c2s=2.5KB  ratio~1523.0\n",
      "- 192.168.9.100:50034 → 23.40.114.93:443  s2c=3.3MB  c2s=43.5KB  ratio~77.3\n",
      "- 192.168.9.100:61321 → 13.107.246.42:443  s2c=2.1MB  c2s=54.2KB  ratio~39.2\n",
      "- 192.168.9.100:51452 → 52.98.200.178:443  s2c=1.6MB  c2s=485.2KB  ratio~3.3\n",
      "- 192.168.9.100:60414 → 23.46.84.203:443  s2c=1.6MB  c2s=2.5KB  ratio~639.7\n",
      "- 192.168.9.100:57473 → 199.232.214.251:443  s2c=1.4MB  c2s=2.7KB  ratio~525.5\n",
      "- 192.168.9.100:53919 → 157.240.243.2:443  s2c=1.2MB  c2s=3.5KB  ratio~363.5\n",
      "- 192.168.9.100:59210 → 188.245.171.22:443  s2c=1.1MB  c2s=5.0KB  ratio~223.4\n",
      "- 192.168.9.100:58054 → 199.232.210.250:443  s2c=1.1MB  c2s=7.2KB  ratio~152.3\n",
      "- 192.168.9.100:60857 → 88.221.213.112:443  s2c=708.8KB  c2s=7.0KB  ratio~101.3\n",
      "- 192.168.9.100:59406 → 77.209.227.66:443  s2c=502.6KB  c2s=3.9KB  ratio~127.3\n",
      "- 192.168.9.100:50563 → 142.251.140.227:443  s2c=476.1KB  c2s=15.9KB  ratio~29.9\n",
      "- 192.168.9.100:50649 → 142.250.200.99:443  s2c=418.4KB  c2s=3.0KB  ratio~138.9\n",
      "- 192.168.9.100:61966 → 184.31.3.35:443  s2c=398.1KB  c2s=3.1KB  ratio~127.2\n",
      "\n",
      "Top dominios (SNI) por bytes bajados (s2c):\n",
      "- outlook.office365.com: 150.1KB\n",
      "- assets.msn.com: 85.1KB\n",
      "- sync.hydra.opendns.com: 46.5KB\n",
      "- cloud-ec-asn.eu.amp.cisco.com: 41.3KB\n",
      "- liveupdate.symantec.com: 31.6KB\n",
      "- clients.config.office.net: 16.4KB\n",
      "- intake.eu.amp.cisco.com: 15.5KB\n",
      "- officeclient.microsoft.com: 15.5KB\n",
      "- ent-shasta-rrs.symantec.com: 15.0KB\n",
      "- storeedgefd.dsx.mp.microsoft.com: 14.0KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import struct\n",
    "import socket\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def ip_to_str(b):\n",
    "    return socket.inet_ntoa(b)\n",
    "\n",
    "def parse_tls_sni(payload: bytes):\n",
    "    \"\"\"\n",
    "    Extrae el primer SNI (server_name) si el payload contiene un TLS ClientHello.\n",
    "    Devuelve dominio (str) o None. Robusto: si algo no cuadra, devuelve None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # TLS record header: ContentType(1)=0x16 handshake, Version(2), Length(2)\n",
    "        if len(payload) < 5 or payload[0] != 0x16:\n",
    "            return None\n",
    "        rec_len = int.from_bytes(payload[3:5], \"big\")\n",
    "        if rec_len <= 0 or 5 + rec_len > len(payload):\n",
    "            # puede venir fragmentado; no forzamos\n",
    "            return None\n",
    "\n",
    "        hs = payload[5:5+rec_len]\n",
    "        # Handshake header: msg_type(1)=0x01 client_hello, length(3)\n",
    "        if len(hs) < 4 or hs[0] != 0x01:\n",
    "            return None\n",
    "        hs_len = int.from_bytes(hs[1:4], \"big\")\n",
    "        if hs_len <= 0 or 4 + hs_len > len(hs):\n",
    "            return None\n",
    "\n",
    "        ch = hs[4:4+hs_len]\n",
    "        # ClientHello: version(2) + random(32) + session_id_len(1) + session_id + cipher_suites_len(2)+... etc\n",
    "        if len(ch) < 2 + 32 + 1:\n",
    "            return None\n",
    "        i = 0\n",
    "        i += 2  # version\n",
    "        i += 32 # random\n",
    "\n",
    "        sess_len = ch[i]\n",
    "        i += 1\n",
    "        if i + sess_len > len(ch):\n",
    "            return None\n",
    "        i += sess_len\n",
    "\n",
    "        if i + 2 > len(ch):\n",
    "            return None\n",
    "        cs_len = int.from_bytes(ch[i:i+2], \"big\")\n",
    "        i += 2\n",
    "        if i + cs_len > len(ch):\n",
    "            return None\n",
    "        i += cs_len\n",
    "\n",
    "        if i + 1 > len(ch):\n",
    "            return None\n",
    "        comp_len = ch[i]\n",
    "        i += 1\n",
    "        if i + comp_len > len(ch):\n",
    "            return None\n",
    "        i += comp_len\n",
    "\n",
    "        # Extensions length\n",
    "        if i + 2 > len(ch):\n",
    "            return None\n",
    "        ext_len = int.from_bytes(ch[i:i+2], \"big\")\n",
    "        i += 2\n",
    "        if i + ext_len > len(ch):\n",
    "            return None\n",
    "\n",
    "        end = i + ext_len\n",
    "        # Iterate extensions: type(2), len(2), data\n",
    "        while i + 4 <= end:\n",
    "            ext_type = int.from_bytes(ch[i:i+2], \"big\")\n",
    "            ext_l = int.from_bytes(ch[i+2:i+4], \"big\")\n",
    "            i += 4\n",
    "            if i + ext_l > end:\n",
    "                return None\n",
    "            ext_data = ch[i:i+ext_l]\n",
    "            i += ext_l\n",
    "\n",
    "            # server_name extension type = 0x0000\n",
    "            if ext_type == 0x0000:\n",
    "                # structure: list_len(2), then entries: name_type(1), name_len(2), name(bytes)\n",
    "                if len(ext_data) < 2:\n",
    "                    return None\n",
    "                list_len = int.from_bytes(ext_data[0:2], \"big\")\n",
    "                if 2 + list_len > len(ext_data):\n",
    "                    return None\n",
    "                p = 2\n",
    "                while p + 3 <= 2 + list_len:\n",
    "                    name_type = ext_data[p]\n",
    "                    name_len = int.from_bytes(ext_data[p+1:p+3], \"big\")\n",
    "                    p += 3\n",
    "                    if p + name_len > len(ext_data):\n",
    "                        return None\n",
    "                    name_bytes = ext_data[p:p+name_len]\n",
    "                    p += name_len\n",
    "                    if name_type == 0:  # host_name\n",
    "                        sni = name_bytes.decode(\"utf-8\", errors=\"ignore\").strip()\n",
    "                        return sni or None\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def parse_pcap_flows_and_sni(path):\n",
    "    \"\"\"\n",
    "    Lee PCAP (little-endian) y produce:\n",
    "    - flow_bytes[(client_ip,client_port,server_ip,server_port)] = {\"c2s\":bytes, \"s2c\":bytes, \"pkts\":n}\n",
    "    - flow_sni[(client_ip,client_port,server_ip,server_port)] = dominio (si se detecta)\n",
    "    Heurística: si vemos ClientHello con SNI en c2s, marcamos server como dst:port\n",
    "    \"\"\"\n",
    "    flow_bytes = defaultdict(lambda: {\"c2s\": 0, \"s2c\": 0, \"pkts\": 0})\n",
    "    flow_sni = {}\n",
    "\n",
    "    with open(path, \"rb\") as f:\n",
    "        gh = f.read(24)\n",
    "        if len(gh) < 24:\n",
    "            raise ValueError(\"PCAP demasiado pequeño\")\n",
    "\n",
    "        while True:\n",
    "            ph = f.read(16)\n",
    "            if len(ph) < 16:\n",
    "                break\n",
    "\n",
    "            ts_sec, ts_usec, incl_len, orig_len = struct.unpack(\"<IIII\", ph)\n",
    "            data = f.read(incl_len)\n",
    "            if len(data) < incl_len:\n",
    "                break\n",
    "\n",
    "            # Ethernet\n",
    "            if len(data) < 14:\n",
    "                continue\n",
    "            eth_type = struct.unpack(\"!H\", data[12:14])[0]\n",
    "            if eth_type != 0x0800:\n",
    "                continue\n",
    "\n",
    "            # IP\n",
    "            if len(data) < 14 + 20:\n",
    "                continue\n",
    "            ip_start = 14\n",
    "            ver_ihl = data[ip_start]\n",
    "            ihl = (ver_ihl & 0x0F) * 4\n",
    "            if ihl < 20 or len(data) < ip_start + ihl:\n",
    "                continue\n",
    "\n",
    "            proto = data[ip_start + 9]\n",
    "            if proto != 6:\n",
    "                continue\n",
    "\n",
    "            src_ip = ip_to_str(data[ip_start+12:ip_start+16])\n",
    "            dst_ip = ip_to_str(data[ip_start+16:ip_start+20])\n",
    "\n",
    "            tcp_start = ip_start + ihl\n",
    "            if len(data) < tcp_start + 20:\n",
    "                continue\n",
    "\n",
    "            src_port, dst_port = struct.unpack(\"!HH\", data[tcp_start:tcp_start+4])\n",
    "            data_offset = (data[tcp_start+12] >> 4) * 4\n",
    "            if data_offset < 20 or len(data) < tcp_start + data_offset:\n",
    "                continue\n",
    "\n",
    "            payload = data[tcp_start+data_offset:]\n",
    "            payload_len = len(payload)\n",
    "\n",
    "            # Identificar dirección del flujo (cliente->servidor vs servidor->cliente):\n",
    "            # Heurística simple: el \"server\" suele ser puerto 443/80/etc. Si dst_port es 443, asumimos c2s.\n",
    "            # Si src_port es 443, asumimos s2c.\n",
    "            # Si ninguno, lo dejamos por \"orden\" estable de endpoints (menos robusto pero ok).\n",
    "            common_server_ports = {443, 80, 8080, 8443, 8000, 21, 20, 22}\n",
    "            if dst_port in common_server_ports and src_port not in common_server_ports:\n",
    "                key = (src_ip, src_port, dst_ip, dst_port)\n",
    "                direction = \"c2s\"\n",
    "            elif src_port in common_server_ports and dst_port not in common_server_ports:\n",
    "                key = (dst_ip, dst_port, src_ip, src_port)  # cliente sería dst, server sería src\n",
    "                direction = \"s2c\"\n",
    "            else:\n",
    "                # fallback: definimos \"cliente\" como endpoint lexicográficamente menor\n",
    "                ep1 = (src_ip, src_port)\n",
    "                ep2 = (dst_ip, dst_port)\n",
    "                if ep1 <= ep2:\n",
    "                    key = (src_ip, src_port, dst_ip, dst_port)\n",
    "                    direction = \"c2s\"\n",
    "                else:\n",
    "                    key = (dst_ip, dst_port, src_ip, src_port)\n",
    "                    direction = \"s2c\"\n",
    "\n",
    "            flow_bytes[key][\"pkts\"] += 1\n",
    "            if direction == \"c2s\":\n",
    "                flow_bytes[key][\"c2s\"] += payload_len\n",
    "                # Intentar SNI solo en c2s (ClientHello suele ir del cliente)\n",
    "                if key not in flow_sni and payload_len >= 20:\n",
    "                    sni = parse_tls_sni(payload)\n",
    "                    if sni:\n",
    "                        flow_sni[key] = sni\n",
    "            else:\n",
    "                flow_bytes[key][\"s2c\"] += payload_len\n",
    "\n",
    "    return flow_bytes, flow_sni\n",
    "\n",
    "def human(n):\n",
    "    # bytes -> texto\n",
    "    for unit in [\"B\", \"KB\", \"MB\", \"GB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.1f}{unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.1f}TB\"\n",
    "\n",
    "def main(path, top_n=20):\n",
    "    if not os.path.exists(path):\n",
    "        print(\"ERROR: archivo no existe\")\n",
    "        return\n",
    "\n",
    "    flow_bytes, flow_sni = parse_pcap_flows_and_sni(path)\n",
    "\n",
    "    print(f\"Flujos TCP detectados (normalizados): {len(flow_bytes)}\")\n",
    "    print(f\"SNI (TLS) detectados: {len(flow_sni)}\\n\")\n",
    "\n",
    "    # Top por bytes s2c (posibles descargas)\n",
    "    ranked = sorted(flow_bytes.items(), key=lambda kv: kv[1][\"s2c\"], reverse=True)\n",
    "\n",
    "    print(f\"Top {top_n} posibles 'descargas' (bytes servidor→cliente = s2c):\")\n",
    "    shown = 0\n",
    "    for key, st in ranked:\n",
    "        if shown >= top_n:\n",
    "            break\n",
    "        if st[\"s2c\"] == 0:\n",
    "            continue\n",
    "        c_ip, c_port, s_ip, s_port = key\n",
    "        sni = flow_sni.get(key)\n",
    "        extra = f\"  SNI={sni}\" if sni else \"\"\n",
    "        ratio = (st[\"s2c\"] / (st[\"c2s\"] + 1))  # +1 para evitar div0\n",
    "        print(f\"- {c_ip}:{c_port} → {s_ip}:{s_port}  s2c={human(st['s2c'])}  c2s={human(st['c2s'])}  ratio~{ratio:.1f}{extra}\")\n",
    "        shown += 1\n",
    "\n",
    "    # Top dominios por total bajado (si hay SNI)\n",
    "    by_domain = Counter()\n",
    "    for key, dom in flow_sni.items():\n",
    "        by_domain[dom] += flow_bytes[key][\"s2c\"]\n",
    "\n",
    "    if by_domain:\n",
    "        print(\"\\nTop dominios (SNI) por bytes bajados (s2c):\")\n",
    "        for dom, b in by_domain.most_common(10):\n",
    "            print(f\"- {dom}: {human(b)}\")\n",
    "    else:\n",
    "        print(\"\\nNo se detectó SNI. Puede ser porque:\")\n",
    "        print(\"- el ClientHello está fragmentado y no cae entero en un paquete\")\n",
    "        print(\"- es QUIC (UDP/443) en vez de TCP\")\n",
    "        print(\"- o la captura empieza tarde (sin el inicio de la conexión)\")\n",
    "\n",
    "# Uso\n",
    "main(r\"descargas.pcap\", top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e833c7-7199-488c-8007-05246256fe4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wireshark-env)",
   "language": "python",
   "name": "wireshark-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
